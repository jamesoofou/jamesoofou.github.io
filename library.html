<!DOCTYPE html>
<html>
  <head>
    <title>jim's web site</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="./style.css" id="main-stylesheet">
  </head>
  <body>
    <a href="./home.html">
  <img src="./castle-static.gif"
       data-gif="./tower.gif" 
       class="hover-gif"
       alt="home">
</a>

<script>
  // Optimized hover GIF handling
  (function () {
      const gifs = document.querySelectorAll('.hover-gif');
      if (!gifs.length) return;

      const dataMap = new WeakMap();

      gifs.forEach((img) => {	  const staticSrc = img.getAttribute('src');
				  const gifSrc = img.dataset.gif;
				  if (!gifSrc) return;

				  dataMap.set(img, { staticSrc, gifSrc, preloaded: false });
			    });

      function bustCache(url) {
	  const sep = url.includes('?') ? '&' : '?';
	  return url + sep + 't=' + Date.now();
      }

      function preloadGif(entry) {
	  if (entry.preloaded) return;
	  const pre = new Image();
	  pre.decoding = 'async';
	  pre.src = bustCache(entry.gifSrc);
	  entry.preloaded = true;
      }

      document.addEventListener('mouseover', onEnter, { passive: true, capture: true });
      document.addEventListener('mouseout', onLeave, { passive: true, capture: true });

      function isEnteringFromOutside(e) {
	  const related = e.relatedTarget;
	  return !related || (related !== e.target && !e.target.contains(related));
      }

      function isLeavingToOutside(e) {
	  const related = e.relatedTarget;
	  return !related || (related !== e.target && !e.target.contains(related));
      }

      function onEnter(e) {
	  const img = e.target;
	  if (!(img instanceof HTMLImageElement)) return;
	  if (!img.classList || !img.classList.contains('hover-gif')) return;
	  if (!isEnteringFromOutside(e)) return;

	  const entry = dataMap.get(img);
	  if (!entry) return;

	  preloadGif(entry);
	  img.src = bustCache(entry.gifSrc);
      }

      function onLeave(e) {
	  const img = e.target;
	  if (!(img instanceof HTMLImageElement)) return;
	  if (!img.classList || !img.classList.contains('hover-gif')) return;
	  if (!isLeavingToOutside(e)) return;

	  const entry = dataMap.get(img);
	  if (!entry) return;

	  img.src = entry.staticSrc;
      }

      if ('IntersectionObserver' in window) {
	  const io = new IntersectionObserver(
	      (entries) => {
		  for (const { isIntersecting, target } of entries) {
		      if (!isIntersecting) continue;
		      const entry = dataMap.get(target);
		      if (!entry) continue;
		      preloadGif(entry);
		      io.unobserve(target);
		  }
	      },
	      { rootMargin: '200px' }
	  );

	  gifs.forEach((img) => io.observe(img));
      }
  })();
</script>    
    
<h1>Library</h1>

<!--
     <li>
     <ul>
     <li>date 2025</li>
     <li><a href="link">title</a></li>
     <li></li>
     <details>
     <summary>notes</summary>
     
     </details>
     </ul>
     </li>
-->
<h2>To Read</h2>
<ul>
    <li>https://www.lesswrong.com/posts/adadYCPFAhNqDA5Ye/processor-clock-speeds-are-not-how-fast-ais-think</li> <li>https://www.complexsystemspodcast.com/episodes/the-great-developer-speed-up-with-joel-becker/</li>
    <li>https://arxiv.org/pdf/2409.09232</li>
    <li>https://www.greaterwrong.com/index?view=all</li>
    <li>http://csinvesting.org/wp-content/uploads/2012/07/the_mckinsey_way.pdf</li>
    <li>https://scottaaronson.blog/</li>
    <li>https://writings.stephenwolfram.com/2015/12/untangling-the-tale-of-ada-lovelace/</li>
    <li>https://irp-cdn.multiscreensite.com/cb9165b2/files/uploaded/The+48+Laws+Of+Power.pdf</li>
</ul>
<!--  -->

<ul>
    <li>
	<ul>
	    <li>Aug 24 2025</li>
	    <li><a href="https://www.lesswrong.com/posts/xLDwCemt5qvchzgHd/scale-was-all-we-needed-at-first?from=feedModal#">Scale Was All We Needed, At First</a></li>
	    <li>Some more fiction about AI (we'll see how good though)</li>
	    <details>
		<summary>notes</summary>
		<p></p>
	    </details>
	</ul>
    </li>

    <li>
	<ul>
	    <li>Aug 23 2025</li>
	    <li><a href="https://en.wikipedia.org/wiki/Nvidia">Nvidia</a></li>
	    <li>Wikipedia article on NVIDIA</li>
	    <details>
		<summary>notes</summary>
		<p>motto: "Our company is thirty days from going out of business."</p>
		<p></p>
	    </details>
	</ul>
    </li>
    <li>
	<ul>    
	    <li>Aug 23 2025</li>
	    <li><a href="https://web.archive.org/web/20171116192021/http://fortune.com/2017/11/16/nvidia-ceo-jensen-huang/">This Man Is Leading an AI Revolution in Silicon Valley—And He’s Just Getting Started</a></li>
	    <li>Article about Jensen Huang</li>
	    <details>
		<summary>notes</summary>
		<p>“Jensen is one of those rare individuals who combines incredible vision with ruthless focus on execution,”</p>
		<p>"For the next couple of decades, the greatest contribution of A.I. is writing software that humans simply can’t write. Solving the unsolvable problems."</p>
		<p>I guess the question is whether he saw this as something others would do, or something NVIDIA would do. Is it possible that NVIDIA will somehow keep up and survive even as Google and others approach AGI?</p>
		<p>But, no, there's little hope of that. Generality and scale is the way to go.</p>
	    </details>
	</ul>
    </li>
    <li>
	<ul>

	    <li>Aug 18 2025</li>
	    <li><a href="https://gwern.net/spaced-repetition">Spaced Repetition for Efficient Learning</a></li>
	    <li>A classic on memorisation</li>
	    <details>
		<summary>notes</summary>
		<p>so spaced repitition is good for motor skills and memorisation of words, not e.g. math skills or something like that</p>
		<p>good for 'indexing', e.g. if need to remember the 100 principles of X, then just remembering a 'key' for each principle is mostly sufficient, then the 'value' will come naturally as my memory is very good, my indexing less good</p>
	    </details>
	</ul>
    </li>
    <li>
	<ul>
	    <li>Aug 16 2025</li>
	    <li><a href="https://unstableontology.com/2025/08/15/a-philosophical-kernel-biting-analytic-bullets/">A philosophical kernel: biting analytic bullets</a></li>
	    <li></li>
	    <details>
		<summary>notes</summary>
		<p></p>
	    </details>
	</ul>
    </li>
    <li>
	<ul>
	    <li>Aug 16 2025</li>
	    <li><a href="https://writings.stephenwolfram.com/2024/06/ruliology-of-the-forgotten-code-10/">Ruliology of the “Forgotten” Code 10</a></li>
	    <li>wolfram</li>
	    <details>
		<summary>notes</summary>
		<p>ok, let's read some more about ruliology</p>
		<p>Wolfram's book 'Idea Makers' supports a thesis that " basically all significant science discoveries" require years of buildup. This could be interesting, having implications on time-horizon analysis and forecasting the arrival of AGI and the timeline of takeoff.</p>
	    </details>
	</ul>
    </li>
    <li>
	<ul>
	    <li>Aug 16 2025</li>
	    <li><a href="https://writings.stephenwolfram.com/2025/08/i-have-a-theory-too-the-challenge-and-opportunity-of-avocational-science/">“I Have a Theory Too”: The Challenge and Opportunity of Avocational Science</a></li>
	    <li>Wolfram, seems to be talking about LLM psychosis</li>
	    <details>
		<summary>notes</summary>
		<p><a href="https://writings.stephenwolfram.com/category/historical-perspectives/">Category: Historical Perspectives</a> looks interesting </p>
		<p>hah, he just promotes 'ruliology', and 'computational essays'. Wouldn't mind looking into this at some point, although it's obviously not a high-EV occupation.</p>
	    </details>
	</ul>
    </li>
    <li>
	<ul>
	    <li>Aug 15 2025</li>
	    <li><a href="https://archive.ph/qnowx">OpenAI Employees Have Stock to Sell</a></li>
	    <li>Very boring, dropped after a few paragraphs, decided I am not a fan Matt Levine's writing</li>
	</ul>
    </li>

    <li>
	<ul>
	    <li>Aug 15 2025</li>
	    <li><a href="https://gwern.net/matt-levine">Why So Few Matt Levines?</a></li>
	    <details>
		<summary>notes</summary>
		<p>I guess just because no one would be at all interested in a Matt Levine of petroleum. Everyone cares about money a lot, ~all of Levine's readers probably invest in some way or would like to. There's no analogue in most other areas. Also, money is just fundamentally an intellectual area. There's probably only so much interesting you can say about most other sectors without it just devolving into finance / politics / various other topics where there <i>are</i> Matt Levines.</p>
		<p>Also, I've decided Matt Levine is not interesting to read.</p>
	    </details>
	</ul>
    </li>
    <li>
	<ul>
	    <li>Aug 15 2025</li>
	    <li><a href="https://archive.ph/3WgjJ">Bet on or Against the Unicorns</a></li>
	    <li>This is just some random article, I'm trying to get to assess Levine</li>
	    <details>
		<summary>notes</summary>
		<blockquote>
		    There is one interesting novelty to this wave of meme stocks, which we discussed last week: ChatGPT. Meme stocks are an internet phenomenon, and in 2021, the way that people consumed the internet was through, you know, the internet. You found out about meme stocks on Reddit, or perhaps YouTube or Twitter. In 2025, many people consume the internet in a distilled form through large language models. If you want to know what stocks to buy, you don’t have to go to Reddit’s WallStreetBets forum; you can go to ChatGPT. ChatGPT has consumed the internet and internalized its patterns of thought, which definitely include “you should YOLO GameStop.” Or OpenDoor, as the case may be.
		</blockquote>
		<p>Is this true? Obviously <i>some</i> people have to be on the 'real' internet (how else would ChatGPT's generations be coordinated enough to move the stock market? well, I could speculate, but in reality...). Is there really some large segment of netizens who get the internet via ChatGPT?</p>
		<blockquote>
		    In 2025, a similar coordination function can perhaps be performed by ChatGPT: A million traders can go to their computers and ask what stocks to buy and be told “OpenDoor” and buy it.
		</blockquote>
		<p>OK, but this seems a little unlikely? Sure, ChatGPT is likely to read various subreddits if you ask for stocks to take a fun gamble on, but how many people actually do that, and would ChatGPT be enthusiastic or cautious? Cautious, I would have thought. Anyway, this is something we can test, so let's test.</p>
		<p>I tested a bit on whatever the model is when we run out of GPT-5 and got results whicih make me more dubious of Levine's theory. Seems like a dumb theory, so if it's not true it lowers my (still-forming) opinion of Levine. Of course, columnists sometimes just pump out random slop to meet their wordcount, so it might not actually reflect poorly on his intellect, but still makes me less likely to want to read his stuff.</p>
		<p>It's just ungrounded LLM-future speculation. Which of course we love at jfund, but it's simultaneously incredibly <i>unimportant</i> speculatin. What's the point of crazy speculation on what doesn't matter? OK, there is some point, which is that you immediately ramp up the skepticism and whittle down your crazed ravings to some core of solid predictions which few if any others have arrived at, and due to your confidence in your superior epistemology you are willing to bet on... but he hasn't done that. Still, reading it adds some entropy to one's thought-processes, I suppose.</p>
	    </details>
	</ul>
    </li>
    <li>
	<ul>
	    <li>Aug 1 2025</li>
	    <li><a href="https://arxiv.org/pdf/2303.10130">GPTs are GPTs: An Early Look at the Labor Market Impact Potential
		of Large Language Models</a></li>
	    <li>Modeling economic impact of LLMs</li>
	    <details>
		<summary>notes</summary>
		<blockquote>General-purpose technologies (e.g. printing, the steam engine) are characterized by widespread proliferation, continuous improvement, and the generation of complementary innovations (Bresnahan and Trajtenberg, 1995; Lipsey et al., 2005).</blockquote>
		<p> OK, so LLMs will be characterised by widespread proliferation (i.e. extreme adoption in multiple sectors), continuous improvement, and the generation of complementary innovations. "Complementary innovations"... such as?</p>
		<blockquote>We use the ONET 27.2 database (ONET, 2023), which contains information on 1,016 occupations, including their respective Detailed Work Activities (DWAs) and tasks. A DWA is a comprehensive action that is part of completing task, such as "Study scripts to determine project requirements." A task, on the other hand, is an occupation-specific unit of work that may be associated with zero, one, or multiple DWAs.</blockquote>
		<p>OK, this is really cool. I can potentially copy their methodology but taking into account capabilities advances in LLMs?</p>
		<p>I should read (Lipsey et al., 2005)</p>
		<p>So, I should see how open each industry sector is to LLM-automation, then look at which portion each sector makes up of the SPX,... but then what? What does this tell us? Well, if <i>n</i>% of a sector is automatable, that tells us a little. But what really matters is to what extent it can be accelerated / sublimated / multiplied / etc., that is, to what extent LLMs can increase the amount and quality of output in that sector. So, I would get an LLM to go through the task list, and evaluate each task for the extent to which an LLM with an 80% time-horizon in the hundreds of hours could increase the quantity, quality according to some rubric.</p>
		<p>It seems to me that one of the main reasosn white-colar jobs will be automated before blue-color jobs is that there simply is not enough robotic machinary to replace billions of human workers yet, whereas there is perhaps, or soon will be enough compute to replace white-colar workers (as more compute comes online and the cost of a given level of intelligence decreases). There will be a robotics explosion, but it will lag behind a little, I suspect.</p>
		<p>Rather than going through the ONET tasks, which seems unlikely to be productive when attempting to predict the impact of >100 hour time horizons on the value of the SPX, I think we should sample 20 companies at random from the SPX and look deeply at how this kind of full-automation of white-colar work would affect them.<p>
		    <p>Also, logically, AI will rarely <i>equal</i> human work output. It will either surpass it or fall short of it. Few roles in these companies are binary in nature, where they are either accomplished successfully or non accomplished. So we have to look at how much employee costs can be reduced, how much productivity will increase, how important employee costs are to the valuation of the company...</p>
		    <p>Also, we should look at what's been published about how a growing economy increases valuations of companies regardless of their own efficiency gains. that is, will there be some feedback relationship where each company becoming more productive and profitable pushes up other companies, which also are more efficient, and which therefore push also the others up?</p>
	    </details>
	    
	</ul>
    </li>
    <li>
	<ul>
	    <li>Aug 1 2025</li>
	    <li><a href="https://jwmason.org/wp-content/uploads/2021/01/Coyle-GDP-ch.-1.pdf">GDP: A Brief But Affectionate History (Chapter One)</a></li>
	    <li>Explains what GDP is</li>
	</ul>
    </li>
    <li>
	<ul>
	    <li>Aug 2 2025</li>
	    <li><a href="https://epoch.ai/gradient-updates/quantifying-the-algorithmic-improvement-from-reasoning-models">Quantifying the algorithmic improvement from reasoning models</a></li>
	    <details>
		<summary>notes</summary>
		reasoning pushed us ahead 2 years, another advancement or two like this and we're golden. The "by 2030 or bust" school of thought about arrival of AGI seems foolish given that even if frontier compute growth slows to a standstill these innovations will likely still be a regular occurrence.
	    </details>
	</ul>
</ul>

  </body>
</html>