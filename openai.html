<!DOCTYPE html>
<html>
  <head>
    <title>jim's web site</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="./style.css" id="main-stylesheet">
  </head>
  <body>
    <p style="font-family: Courier, monospace; font-size: 22px;">
    <a href="./index.html" style="font-family: Courier monospace; font-size: 22px;">&#x27F5;</a>
    
<div style="font-family: Courier, monospace; font-size: 22px;">
    <h1>The State of OpenAI</h1>

    <p>(31/oct/2025)</p>
    
    <p>Notes on <a href="https://youtu.be/ngDCxlZcecw?si=nqjD-8Qw16sH28Xk">Sam, Jakub, and Wojciech on the future of OpenAI with audience Q&A</a>.</p>

    <p>OpenAI is "a research organisation working on automating research".</p>

    <p>OpenAI believes that time horizons will continue to extend rapidly. OpenAI sees "orders and orders of magnitude to go" scaling test-time compute.</p>

    <img src="openai1.png">

    <p>OpenAI's internal goal to automate AI research by 2028 March is interesting. By naive extrapolation we'd be at METR-80 of 30h at that point. They probably just did a naive extrapolation and didn't account for hyperexponentaility. Reality will be a lot crazier. Also, it's not clear that human time-horizons actually extend beyond the low tens of hours.</p>

    <img src="openai2.png">

    <p>"We have quite strong expectations for our next models, we expect quite rapid progress over the next couple months and a year".</p>

    <p>The way this works is we develop a lot of pieces, each a hard-won victory, and we know that when we put them together we will have something quite impressive, we're able to predict this fairly well. Part of our goal today is to say that we have a lot of those pieces (He's talking about "a tremendously important step forward in capability")</p>

    <p>OpenAI is promising a big leap forward within the next 6 months. Expect improvements in all areas, and in particular in creative writing, mathematics, science, and coding.</p>

    <p>Contrast this to Alphabet's Sundar's statement on Gemini 3.0:</p>

    <blockquote>I'm incredibly impressed by the pace at which the teams are executing and the pace at which we are improving these models. It also is true, at the same time, that each of the prior models you're trying to get better over is now getting more and more capable. I think both the pace is increasing, but sometimes we are taking the time to put out a notably improved model. I think that may take slightly longer. I do think the underlying pace is phenomenal to see. I'm excited about our Gemini 3.0 release later this year.</blockquote>

    <p>Not clear how much to read into Sundar's statement. Maybe he's holding his cards close to his chest. Maybe Gemini 3.0 really was not a big enough jump at first so they had to keep iterating on it. In which case it sounds like OA is ahead on the LLM front. Being long Microsoft (which owns 27% of OpenAI) seems like a good idea.</p>

</div>

  </body>
</html>