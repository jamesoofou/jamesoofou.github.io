<!DOCTYPE html>
<html>
  <head>
    <title>jim's web site</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="./style.css" id="main-stylesheet">
  </head>
  <body>
    <p style="font-family: Courier, monospace; font-size: 22px;">
    <a href="./index.html" style="font-family: Courier monospace; font-size: 22px;">&#x27F5;</a>
    
<div style="font-family: Courier, monospace; font-size: 22px;">
    <h1>TPUs</h1>
    <p>I was reading vladimir_nesov's recent comments on lesswrong, e.g. <a href="https://www.lesswrong.com/posts/fdCaCDfstHxyPmB9h/vladimir_nesov-s-shortform?commentId=uukkBC7CGsAha7xDM">this one</a></p>
    <p>Google's Trillium TPUs enable larger scale-up worlds than NVIDIA's B200 chips, so companies with access to Google's chips will be able to efficiently serve much larger models than those which only have access to NVIDIA chips. This will be true until late 2026 (September 2026), at which point GB200s will come online at scale. But by then Google's Ironwood chips will be at GW scale and they'll be well ahead still.</p>
    <p>This opens up a future in which Google is just able to offer larger models than anyone else for the foreseeable future. Model size is an important factor of model intelligence so this is a factor which contributes significantly towards Google being the favourite in the race to RSI AI.</p>
</div>

  </body>
</html>